DynamoDB is a fully-managed, NoSQL database provided by Amazon Web Services.

When to use DynamoDB?
  - Hyper-scale applications
  - Hyper-ephemeral compute (aka serverless) DynamoDB is perfect for applications that are serverless.

Core Concepts in DynamoDB
  - Table
    It is a grouping of records that conceptually belong together.
  - Item
    An item is a single record in a DynamoDB table. It is comparable to a row in a relational database or a document in MongoDB.
  - Attributes
    A DynamoDB item is made up of attributes, which are typed data values holding information about the element.
    When you write an item to DynamoDB, each attribute is given a specific type. There are ten different data types in DynamoDB. It’s
    helpful to split them into three categories:
      - Scalars: Scalars represent a single, simple value, such as a username(string) or an age(number). There are 5 scalar types:
                 string, number, binary, boolean and null.
      - Complex: Complex types are the most flexible kind of attribute, as they represent groupings with arbitrary nested attributes.
                 There are two complex types: lists and maps.
      - Sets: Sets are a powerful compound type that represents multiple, unique values. They are similar to sets in your favorite programming language. 
              Each element in a set must be the same type, and there are three set types: string sets, number sets, and binary sets.
  - Primary Keys: When creating a DynamoDB table, you must declare a primary key for your table. Each item in your table must include the primary key.
  - Secondary indexes: Secondary indexes allow you to reshape your data into another format for querying, so you can add additional 
                           access patterns to your data.

PRIMARY KEYS
Types of primary keys
  - Simple primary keys: which consist of a single element called a partition key.
  - Composite primary keys: which consist of two elements, called partition key and sort key.

The type of primary key you choose will depend on your access patterns.
A simple primary key allows you to fetch only a single item at a time.
Composite primary keys, on the other hand, enable a "fetch many" access pattern. With a composite primary key, you can use the
Query API to grab all items with the same partition key.

SECONDARY INDEXES
Types of secondary indexes
  - Local secondary indexes
  - Global secondary indexes
  
A local secondary index uses the same partition key as your tables primary key but a different sort key.
With global secondary index, you can choose any attributes you want for your partition key and your sort key.

Item Collection
An item collection refers to a group of items that share the same partition key in either the base table or a secondary index.
DynamoDB partitions your data across a number of nodes in a way that allows for consistent performance as you scale. However, all items with the same
partition key will be kept on the same storage node.

-------------------------------------------------------------------------------------------------------------------------------------------------------
DynamoDB Stream
A DynamoDB stream is an ordered flow of information about changes to items in a DynamoDB table. 
When you enable a stream on a table, DynamoDB captures information about every modification to data items in the table.
The combination of DynamoDB Streams with serverless compute with AWS Lambda gives you a fully-managed
system to react to database changes.

Time-to-live(TTL)
TTL's allow you to have DynamoDB automatically delete items on a per-item basis. This is a great option for storing short-term 
data in DynamoDB.

Partitions
Partitions are the core storage units underlying your DynamoDB table.
We noted before that DynamoDB is built for infinite scale, and it does that by sharding your data across multiple server
instances. Each item collection will be in a particular partition, and this will enable fast queries on multiple items.

Consistency
Each partition in DynamoDB is made up of 3 nodes.
1 primary node and 2 secondary nodes.
When you do a write operation
  - DynamoDB request router takes the partition key from the request
  - hashes the partition key and finds the right partition
  - writes to the primary node in the partition
  - responds to the client saying the wite operation is complete
  - asynchronously replicates the item from the primary to secondary nodes.
The reason for having secondary nodes
  - Provide fault-tolerance in case the primary node goes down
  - These secondary nodes can serve read requests to alleviate pressure on the primary node

** Problem **
Because writes are asynchronously replicated from the primary to secondary nodes, the secondary might be a little behind the primary node.

Two consistency options available with DynamoDB
  - Strong consistency: any item you read from DynamoDB will reflect all writes that occurred prior to the read being executed.
  - Eventual consistency(default): Its possible the item(s) you read will not reflect all prior writes.
  
There are two times you need to think about consistency with DynamoDB
  - Whenever you are reading data from the base table, you can choose your consistency level. By default its eventually-consistent read.
  - You should think about consistency when choosing your secondary index type. 

------------------------------------------------------------------------------------------------------------------------------------------------
DynamoDB Limits
  - Item size limits
    A single DynamoDB item is limited to 400KB of data.
  - Query and Scan request size limits
    Query and Scan, the two "fetch many" API actions will read a maximum of 1MB of data from your table.
  - Partition throughput limits
    A single partition can have a maximum of 3000 Read Capacity Units or 1000 Write Capacity Units.
    Thus you will need to be doing 3000 reads per second for a given partition key to hit these limits.
  - Item collection limits
    An item collection refers to all items with a given partition key. A single item collection cannot be larger than 10GB.
  
------------------------------------------------------------------------------------------------------------------------------------------------
Overloading Keys
One unique quirk of modeling with DynamoDB is that you will often include different types of entities in a single table.

              Primary Key                       Attributes
Partition Key: PK    Sort Key: SK         OrgName        Subscription Level
ORG#INFOSYS          ORG#INFOSYS          Infosys        Enterprise
                                          UserName       Role
ORG#INFOSYS          USER#ANTONY          Antony C       Employee
ORG#INFOSYS          USER#AASHISH         Aashish A      Employee

In the above table, we have 2 different types of entities, Users and Organisations.
Organisations and Users have a different set of attributes.
Look at the way the partition key and the sort key are maintained.
This concept of using generic names for your primary keys and using different values depending on the type of item is known as
overloading your keys.

================================================================================================================================================
DynamoDB API's

API's split into 3 categories
1: Item-based actions - operating on specific items
2: Queries - operating on an item collection
3: Scans - operating on the whole table

----------------------------------------------------------------------------------------------------------------------------------
Item-based actions
There are 4 core API actions for item-based actions
  - GetItem: used for reading a single item from a table
  - PutItem: used for writing an item to a table. This can completely overwrite an existing item with the same key, if any.
  - UpdateItem: used for updating an item in a table. This can create a new item if it doesn’t previously exist, or it can add,
                remove, or alter properties on an existing item.
  - DeleteItem: used for deleting an item from a table.
  
3 rules around item-based actions
  - Full primary key must be specified in your request
  - All actions to alter data - writes, updates or delete must use an item-based action.
  - All item-based actions must be performed on your main table, not a secondary index.

2 sub-categories of single-item API
  - Batch actions
  - Transaction actions
These categories are used for reading and writing multiple DynamoDB items in a single request. While these operate on
multiple items at once, I still classify them as item-based actions because you must specify the exact items on which you want to
operate.

Batch action: your reads or writes can succeed or fail independently. The failure of one write
              won’t affect the other writes in the batch.
Transaction action: all of your reads or writes will succeed or fail together. The failure of a single
                    write in your transaction will cause the other writes to be rolled back.
  
-----------------------------------------------------------------------------------------------------------------------------------
Query API

The Query API action lets you retrive multiple items with the same partition key.

A Query operation using the AWS JavaScript SDK

const inputParams = {
    TableName: "test_MoviesAndActors",
    KeyConditionExpression: "#actor = :actor AND #movie BETWEEN :a AND :m",
    ExpressionAttributeNames: {
      "#actor": "Actor",
      "#movie": "Movie",
    },
    ExpressionAttributeValues: marshall({
      ":actor": "Tom Hanks",
      ":a": "A",
      ":m": "M",
    }),
  };
  
const data = await dbClient.send(new QueryCommand(inputParams));

----------------------------------------------------------------------------------------------------------------------------------
Scan API
A Scan will grab everything in a table.
The times you may consider using the scan operation.
  - When you have a small table
  - When you're exporting all data from your table to a different system
  - In exceptional situations, where you have specifically modeled a sparse secondary index in a way that expects a scan.

DON'T USE SCANS
----------------------------------------------------------------------------------------------------------------------------------
How DynamoDB enforces efficiency?
DynamoDB uses partitions, or small storage nodes of about 10GB, to shard your data across multiple machines. The
sharding is done on the basis of the partition key. Thus, if the DynamoDB request router is given the partition key for an item, it
can do an O(1) lookup in a hash table to find the exact node or set of nodes where that item resides.
This is why all the single-item actions and the Query action require a partition key.

===================================================================================================================================
Expression Attribute names and values

In the query operation example above in the KeyConditionExpression we notice two placeholders
Ones that start with # and other placeholders that start with :
The ones that start with a color(:) are expression attribute values. Look at the ExpressionAttributeValues property in our request.

Why can’t we just write our attribute values directly into the expression?
Remember that each attribute value in DynamoDB has a type. DynamoDB does not infer this type—you must explicitly provide it
when you make a request.

The placeholders that start with # are expression attribute names.
These are used to specify the name of the attribute you are evaluating in your request.

Why can’t we just write our attribute name directly into the expression?
Well you can write the attribute name directly into your expression. That said, there are a few times when the use of
ExpressionAttributeNames is required. The most common reason is if your attribute name is a reserved word in DynamoDB. There
are 573 reserved words in DynamoDB, and many of them will conflict with normal attribute names.

-----------------------------------------------------------------------------------------------------------------------------------
Don't use an ORM
Object-relational mappers (ORMs) are popular tools when using relational databases in your application code.
There is an exceptional library called DynamoDB Toolbox. DynamoDB Toolbox is explicitly not an ORM. However, it does help you define entity
types in your application and map those to your DynamoDB table.

-----------------------------------------------------------------------------------------------------------------------------------
Understand the optional properties on individual requests

1: ConsistentRead
   By default, reads from DynamoDB are eventually consistent, meaning that the reads will
   likely, but not definitely, reflect all write operations that have happened before the given read operation.
   To get a strongly-consistent read, you need to set ConsistentRead=True in your API call. 
   The ConsistentRead property is available on four operations:
   - GetItem
   - BatchGetItem
   - Query
   - Scan
   
   Opting into a strongly-consistent read consumes more read request units than using an eventually-consistent read.
   If you are using a local secondary index, you may opt into strong consistency by passing ConsistentRead=True. 
   All reads from a global secondary index are eventually consistent.
  
2: ScanIndexForward
   This property is available only on the Query operation, and it controls which way you are reading results from the sort key.
   Lets say our table has a partition key as the sensor id and the sort key is the timestamp.
   DynamoDb orders its sort key in ascending order. Imagine your sensor reported data every minute. After a single day
   of operation, your sensor would have 1440 readings. However, to find the most recent 20 readings, you would need to page through
   all 1440 readings until you got to the end. That would consume a lot of read capacity!
   
   The ScanIndexForward property allows you to flip the direction in which DynamoDB will read your sort key. If you set
   ScanIndexForward=False, then DynamoDB will read your sort key in descending order.
   
3: ReturnValues
   It will be helpful to receive additional information about existing or updated item from DynamoDb after certail api call finishes.
   The API's with th ReturnValues property are 
   - PutItem
   - UpdateItem
   - DeleteItem
   - TransactWriteItem
   
   There are a few different available options for the ReturnValues property:
   - NONE: Return no attributes from the item. This is the default setting.
   - ALL_OLD: Return all the attributes from the item as it looked before the operation was applied.
   - UPDATED_OLD: For any attributes updated in the operation, return the attributes before the operation was applied.
   - ALL_NEW: Return all the attributes from the item as it looks after the operation is applied.
   - UPDATED_NEW: For any attributes updated in the operation, return the attributes after the operation is applied.
   
4: ReturnConsumedCapacity
   This property will not change the items that will be returned from your request. Rather, it is an option to include additional metrics with your request.
   The ReturnConsumedCapacity property is an optional property that will return data about the capacity units that were used by the
   request.
   You can specify ReturnConsumedCapacity=INDEXES, which will include detailed information on not only the consumed
   capacity used for your base table but also for any secondary indexes that were involved in the operation. If you don’t need that level of
   precision, you can specify ReturnConsumedCapacity=TOTAL to simply receive an overall summary of the capacity consumed in the
   operation.
   Use cases:
   - You may use these metrics if you are in the early stages of designing your table.
   - You have a pricing scheme where users are charged according to the size of read or write items.
   
5: ReturnItemCollectionMetrics
   If your table has a local secondary index, then a single item collection cannot be larger than 10GB in size. If
   you try to write an item that would exceed this limit, the write will be rejected.
   To give yourself advanced warning of this problem, you can use the ReturnItemCollectionMetrics property on all write-based API
   calls.
   If you don’t have a local secondary index, there are no limits on the size of an item collection.
   
=================================================================================================================================================
DynamoDB Expressions
Expressions are statements that operate on your items. They’re sort of like mini SQL statements.

There are five types of expressions in DynamoDB:
1: Key Condition Expressions: Used in the Query API call to describe which items you want to retrieve in your query.
2: Filter Expressions: Used in Query and Scan operations to describe which items should be returned to the client after
                       finding items that match your key condition expression.
3: Projection Expressions: Used in all read operations to describe which attributes you want to return on items that were read.
4: Condition Expressions: Used in write operations to assert the existing condition (or non-condition) of an item before writing to it.
5: Update Expressions: Used in the UpdateItem call to describe the desired updates to an existing item.

- Key Condition Expressions
  It is used on every Query operation to describe which items you want to fetch.
  Examples
  ------------------------------------------------------------------------------
  const inputParams = {
    TableName: "test_MoviesAndActors",
    KeyConditionExpression: "#actor = :actor",
    ExpressionAttributeNames: {
      "#actor": "Actor",
    },
    ExpressionAttributeValues: marshall({
      ":actor": "Natalie Portman",
    }),
  };
  
  In the example above our KeyConditionExpression expresses our desire to retrieve all items with Natalie Portman as the actor.
  
  --------------------------------------------------------------------------------
  const inputParams = {
    TableName: "test_MoviesAndActors",
    KeyConditionExpression: "#actor = :actor AND #m < :title",
    ExpressionAttributeNames: {
      "#actor": "Actor",
      "#m": "Movie"
    },
    ExpressionAttributeValues: marshall({
      ":actor": "Natalie Portman",
      ":title": "N"
    }),
  };
  
  
  In this example, we are specifying that the Movie value must come before the letter "N".

-----------------------------------------------------------------------------------
  const inputParams = {
    TableName: "test_customerTransaction",
    KeyConditionExpression: "#c = :c AND #ot BETWEEN :start and :end",
    ExpressionAttributeNames: {
      "#c": "CustomerId",
      "#ot": "OrderTime",
    },
    ExpressionAttributeValues: marshall({
      ":c": "1",
      ":start": moment().startOf("month").format(),
      ":end": moment().endOf("month").format(),
    }),
  };
  
  In addition to our partition key specifying the CustomerId we want, we also use the BETWEEN operator with the sort key to find all items
  between our given time range.
====================================================================================================================
  - Filter Expressions
    A filter expression is available for both Query and Scan operations.
    The key difference with a filter expression vs. a key condition expression is that a filter expression can be applied on any attribute
    in the table, not just those in the primary key.
    Examples:
    -------------------------------------------------------------------------------
    const inputParams = {
    TableName: "test_MoviesAndActors",
    KeyConditionExpression: "#actor = :actor",
    FilterExpression: "#year = :year",
    ExpressionAttributeNames: {
      "#actor": "Actor",
      "#year": "Year",
    },
    ExpressionAttributeValues: marshall({
      ":actor": actorName,
      ":year": 2000,
    }),
  };
   
   In the example above we filter out all the movies by actorName made in year 2000.
   --------------------------------------------------------------------------------
   At first we may think FilterExpression is the solution to all our access patterns, but its got problems.
   DynamoDb will read items from the table based on the KeyConditionExpression, if a FilterExpression is present
   it will remove items that dont match and then return the final set of items.
   Step 1, where the items are read DynamoDb applies the max of 1MB data rule before even thinking about Filter Expression.
   
   If you want to filter your data, you need to make sure your access patterns are built directly into your primary keys.
   
=============================================================================================================================
  - Projection Expressions
    A projection expression is similar to a filter expression in that its main utility is in reducing the amount of data sent over the wire in your
    response. We may not need certain attributes everytime we query, we can use projection expression to filter out these attributes in our response.
    
    const inputParams = {
    TableName: "test_MoviesAndActors",
    KeyConditionExpression: "#actor = :actor",
    ProjectionExpression: "#actor, #movie",
    ExpressionAttributeNames: {
      "#actor": "Actor",
      "#movie": "Movie",
    },
    ExpressionAttributeValues: marshall({
      ":actor": actorName,
    }),
  };
  
    In the example above we will only get Actor and Movie attributes in our response and every other attribute will be removed.
==============================================================================================================================
   - Condition Expressions
     Condition expressions are available on every operation where you will alter an item—PutItem, UpdateItem, DeletetItem, and their
     batch and transactional equivalents. 
     They allow you to assert specific statements about the status of the item before performing the write operation. If the condition 
     expression evaluates to false, the operation will be cancelled.
     Use Cases
      - To avoid overwriting an existing item when using PutItem
      - To prevent an UpdateItem operation from putting an item in a bad state, such as reducing an account balance below 0
      - To assert that a given user is the owner of an item when calling DeleteItem
      
      Comparison operators
      = - equals
      <> - not equals
      < - less than
      > - greated than
      <= - less than and equal
      >= - greater than and equal
      BETWEEN - between a and b
      IN - in (a, b)
      
      Logical operators
      AND
      OR
      NOT
      
      Functions
      attribute_exists(): Used to assert that a given attribute exists
      attribute_not_exists(): Just the opposite—assert that an attribute does not exist on the item.
      attribute_type(): Used to assert that an attribute is of a particular type
      begins_with(): Assert that an attribute value begins with a particular substring
      contains(): Assert that a string contains a particular substring, or that a set contains a particular value.
      size(): Allows you to assert various properties about the size of an attribute value. For things like strings or binary values, it’s the
              length of the string or number of bytes in the binary value. For things like lists, maps, or sets, it returns the number of elements
              in a set.
  ------------------------------------------------------------------------------------------------------------------------------------------
  - Preventing overwrites or checking for uniqueness
    const inputParams = {
      TableName: "test_customerTransaction",
      Item: marshall({
        CustomerId: cId,
        Name: "Boba Fett",
        CreatedAt: new Date(),
      }),
      ConditionExpression: "attribute_not_exists(#username)",
      ExpressionAttributeNames={
        "#username": "Username"
      }
    }
    
    We specify the attributes we want to set on our item, but we also include a ConditionExpression parameter that asserts that there is
    no item with the same username.
    
  - Limiting in-progress items
    {
      TableName='WorkQueue',
      Key={
        "PK": { "S": "Tracker" }
      }
      ConditionExpression: "size(#inprogress) <= 10",
      UpdateExpression="Add #inprogress :id",
      ExpressionAttributeNames={
        "#inprogress": "InProgress"
      },
      ExpressionAttributeValues={
        ":id": { "SS": [ <jobId> ] }
      }
    }
    
    In the example above we are limiting the size of the InProgress set to be less than or equal to 10.
    
  - Asserting user permissions on an item
  {
    TableName='BillingDetails',
    Key={
      "PK": { "S": 'Amazon' }
    }
    ConditionExpression="contains(#a, :user)",
    UpdateExpression="Set #st :type",
    ExpressionAttributeNames={
      "#a": "Admins",
      "#st": "SubscriptionType"
    },
    ExpressionAttributeValues={
      ":user": { "S": 'Jeff Bezos' },
      ":type": { "S": 'Pro' }
    }
  }
  
  In the example above we are checking if the admins set has the user named Jeff Bezos and only if its true continue with the
  update operation.
  
  - Checks across multiple items
    {
      TransactItems=[
        {
          "ConditionCheck": {
              "Key": {
                  "PK": { "S": "Admins#<orgId>" }
              },
              "TableName": "SaasApp",
              ConditionExpression: "contains(#a, :user)",
              ExpressionAttributeNames={
                  "#a": "Admins"
              },
              ExpressionAttributeValues={
                  ":user": { "S": <username> }
              }
          }
        },
        {
          "Delete": {
            "Key": {
              "PK": { "S": "Billing#<orgId>" }
            },
            "TableName": "SaasApp"
           }
        }
      ]
   }
   
   In the example above we are using TransactWriteItemsCommand
   TransactItems, is an array of write items we want to complete and a ConditionCheck.
   The ConditionCheck can be on another item in the same table or another item in a different table.
   If the ConditionCheck fails all the write operations will be abandoned.
   
=====================================================================================================================================
  - Update Expressions
    In an update expression, you need to state the changes you want to make. There are four verbs for stating these changes
      - SET: Used for adding or overwriting an attribute on an item. Can also be used to add or subtract from a number attribute
      - REMOVE: Used for deleting an attribute from an item or deleting nested properties from a list or map
      - ADD: Used for adding to a number attribute or inserting an element into a set attribute
      - DELETE: Used for removing an element from a set attribute
      
    If you have multiple operations for a single verb, you only state the verb once and use commas to separate the clauses, as shown below:
    UpdateExpression="SET Name = :name, UpdatedAt = :updatedAt"
    
    In the operation above, we’re setting both the Name and UpdatedAt attributes to new values.
    
    If you want to include multiple verbs in the same update expression, you don’t need anything to separate the verb clauses.
    The presence of reserved verb words will be enough. For example:
    UpdateExpression="SET Name = :name, UpdatedAt = :updatedAt REMOVE InProgress"

    In the example above, we’re using our same SET clause to update the Name and UpdatedAt properties, and we’re using a REMOVE
    clause to delete the InProgress attribute from our item.
    
--------------------------------------------------------------------------------------------------------------------------------------
  -  Updating or setting an attribute on an item
  
     const updateInputs = {
        TableName='Users',
        Key={
          "Username": { "S": "python_fan" }
        }
        UpdateExpression="SET #picture :url",
        ExpressionAttributeNames={
          "#picture": "ProfilePictureUrl"
        },
        ExpressionAttributeValues={
          ":url": { "S": <https://....> }
        }
     }

---------------------------------------------------------------------------------------------------------------------------------------
 -  Deleting an attribute from an item
 
    const removeAttribute = {
      TableName='Users',
      Key={
        "Username": { "S": "python_fan" }
      }
      UpdateExpression="REMOVE #picture",
      ExpressionAttributeNames={
        "#picture": "ProfilePictureUrl"
      }
    }
    
----------------------------------------------------------------------------------------------------------------------------------------
  - Incrementing a numeric value
    
    const updateInputs = {
      TableName='PageViews',
      Key={
        "Page": { "S": "ContactUsPage" }
      }
      UpdateExpression="SET #views = #views + :inc",
      ExpressionAttributeNames={
        "#views": "PageViews"
      },
      ExpressionAttributeValues={
        ":inc": { "N": "1" }
      }
    }
    
---------------------------------------------------------------------------------------------------------------------------------------
 - Adding a nested property
 
 const updateInputs = {
    TableName='Users',
    Key={
      "Username": { "S": "python_fan" }
    }
    UpdateExpression="SET #phone.#mobile :cell",
    ExpressionAttributeNames={
      "#phone": "PhoneNumbers",
      "#mobile": "MobileNumber"
    },
    ExpressionAttributeValues={
      ":cell": { "S": "+1-555-555-5555" }
    }
 }
 
 
----------------------------------------------------------------------------------------------------------------------------------------
- Adding and removing from a set
  
  const updateInputs = {
    TableName="SaasApp",
    Key={ "PK": { "S": "Admins#<orgId>" },
    UpdateExpression="ADD #a :user",
    ExpressionAttributeNames={
      "#a": "Admins"
    },
    ExpressionAttributeValues={
      ":user": { "SS": ["an_admin_user"] }
    }
  }
  
========================================================================================================================================
Data Modeling in DynamoDB

- Create an entity-relationship diagram(ERD)
  An entity-relationship diagram is just like it sounds—a diagram that lists the different entities in your application and how they relate to
  each other.
  
- Define your access patterns
  There are two different strategies you can use for building these access patterns.
  - One is the API-centric approach, you list out each of the API endpoints you want to support in your application, as well as the expected shape you
    would like to return in your response.
  - The second approach for building your access patterns is the UI centric approach. With the UI-centric approach, you look at each of the
    screens in your application and the URLs that will match those screens.
    
- Model your primary key structure
  Model the primary key using the following steps.
  - Create an entity chart that is used to track the different types of items in the table.
    
    -------------------------------
    Entity         |  PK   |    SK
    -------------------------------
    Repo           |       |
    Issue          |       |
    Pull Request   |       |
    
 - The second step is to decide on a simple or composite primary key.
 - The last step is to start designing the primary key format for each entity type.
    - Consider what your client will know at read time
    - Use primary key prefixes to distinguish between entity types
      
      Entity           PK                         SK
      Customer         CUSTOMER#<CustomerId>      METADATA#<CustomerId>
      CustomerOrder    ORDER#<OrderId>            METADATA#<OrderId>
      
      This will help you maintain clarity as you build out your access patterns chart and will serve as a nice artifact for development and
      post-development.
  
- Handle additional access patterns with secondary indexes and streams
  You won’t always be able to model everything with your primary key.
  That’s where you start thinking about secondary indexes. Secondary indexes are a powerful tool for enabling
  additional read patterns on your DynamoDB table.
  Use generic attribute names like GSI1PK and GSI1SK for your secondary indexes and handle multiple access patterns
  within a single secondary index.

============================================================================================================================================
Single-table design

Since there are no joins in DynamoDB we cannot use multiple tables in our design.
We need to pre-join the data into item collecions.
If you need to retrieve multiple heterogeneous items in a single request, you organize
those items so that they are in the same item collection.

Downsides of Single-table design
- The steep learning curve to understand single-table design.
- The inflexibility of adding new access patterns.
- The difficulty of exporting your tables for analytics.

When not to use single-table design?
Whenever you need query flexibility and/or easier analytics more than you need blazing fast performance.
- in new applications where developer agility is more important than application performance.
- in applications using GraphQL.

============================================================================================================================================
Data Modeling to Implementation

- Separate application attributes from your indexing attributes
{
  "PK": { "S": "USER#alexdebrie" },
  "SK": { "S": "USER#alexdebrie" },
  "GSI1PK": { "S": "ORG#facebook" },
  "GSI1SK": { "S": "USER#alexdebrie" },
  "Username": { "S": "alexdebrie" },
  "FirstName": { "S": "Alex" },
  "LastName": { "S": "DeBrie" },
  "OrganizationName": { "S": "Facebook" },
  ...
}

Notice that the first four attributes are all related to DynamoDb data model but have no meaning in my application business logic. These
are "indexing attributes" as they're only there for indexing your data in DynamoDb.

-----------------------------------------------------------------------------------------------------------------------------
- Implement your data model at the very boundary of your application 
We notice that an item returned from DynamoDb has values in a map which has the type of each attribute.
We cannot work with nested attributes and hence we need to abstract the data model to the edge of the application and reuse it to abstract 
the type conversions. Or simply use a dynamodb library which does all that.

------------------------------------------------------------------------------------------------------------------------------
- Don't reuse attributes across multiple indexes
For each global secondary index you use, give it a generic name of GSI<Number>. Then, use GSI<Number>PK and GSI<Number>SK for your attribute types.

------------------------------------------------------------------------------------------------------------------------------
- Add a 'Type' attribute to every item

------------------------------------------------------------------------------------------------------------------------------
- Write scripts to help debug access patterns
Rather than using the DynamoDb console, write small scripts that can be used to debug your access patterns.
These scripts can be called via a command-line interface in the terminal. Write these scripts at the same time you're implementing your data model.

-------------------------------------------------------------------------------------------------------------------------------
- Shorten attribute names to save storage
Use short attributes like 'u' for username, 'fn' for first name etc.
This pattern should be considered for large tables.

================================================================================================================================
Strategies for one-to-many relationships

Strategy 1
Denormalization by using a complex attribute
Lists and maps are complex attributes in DynamoDb. In an e-commerce site a user can have multiple addresses.
Storing these addresses in a complex attribute like a map makes our item denormalized. Hence this is a one-to-many mapping.
One user to many addresses. However, there are two factors to consider when deciding whether to handle a one-to-many relationship by
denormalizing with a complex attribute:
 - Do you have any access patterns based on the values in the complex attribute?
   Will there be a situation where we want to fetch the user details using the address? If the answer is no, we
   are good to use this strategy.
 - Is the amount of data in the complex attribute unbounded?
   A single DynamoDB item cannot exceed 400KB of data. If the amount of data that is contained in your complex attribute is
   potentially unbounded, it won’t be a good fit for denormalizing and keeping together on a single item.
   Will the user have infinite addresses? If the answer is no, we are good to use this startegy.
 
-------------------------------------------------------------------------------------------------------------------------------------
Strategy 2
Denormalization by duplicating data
Lets say there is an author who has authored several books. We want for some odd reason, to store the date of birth of the author on all the book items.
Well its data that we are duplicating but its fine.
Two main questions you ask when considering this strategy
 - Is the duplicated information immutable?
   Dta of birth doesn't change, its immutable and its totally fine if its duplicated.
 - If the data does change, how often does it change and how many items include the duplicated information?
 
-------------------------------------------------------------------------------------------------------------------------------------
Strategy 3
Composite primary key + the Query API action
Its probably the most common one-to-many strategy. It uses a composite primary key plus the Query API to fetch an object and its related 
sub-objects.

-------------------------------------------------------------------------------------------------------------------------------------
Strategy 4
Secondary index + the Query API action
Its possible that we have a table that has a one-to-many mapping for a company and its users.
What if we want another one-to-many mapping for user to service tickets raised by the user. Here we will nead a Global Secondary Index.

PK           | SK            | GSI1PK                    | GSI1SK        | email                        | createdDate
ORG#INFOSYS  | USER#ANTONY   | ORG#INFOSYS#USER#ANTONY   | USER#ANTONY   | antony.chiramel@infosys.com  | 28/12/2022
               USER#AASHISH  | ORG#INFOSYS#USER#AASHISH  | USER#AASHISH  | aashish.ah@infosys.com       | 01/01/2023
TICKET#1212  | TICKET#1212   | ORG#INFOSYS#USER#ANTONY   | TICKET#1212   |                              | 29/12/2022

Our primary table will look like above
If we look at the Global Secondary Index table

GSI1PK                    |  GSI1SK       | PK          | SK           | createdDate  | email
ORG#INFOSYS#USER#ANTONY   |  TICKET#1212  | TICKET#1212 | TICKET#1212  | 29/12/2022   |
                          |  USER#ANTONY  | ORG#INFOSYS | USER#ANTONY  | 28/12/2022   | antony.chiramel@infosys.com
                          
Since we now have a GSI with a new primary key, we can use its partition key to query all the tickets raised by the user.

--------------------------------------------------------------------------------------------------------------------------------------
Strategy 5
Composite sort keys with hierarchical data
In the last two strategies, we saw some data with a couple levels of hierarchy—an Organization has Users, which create Tickets. But
what if you have more than two levels of hierarchy? You don’t want to keep adding secondary indexes to enable arbitrary levels of
fetching throughout your hierarchy.

We could solve this problem by using a composite sort key.

PK         | SK                  | Street
INDIA      | KL#THRISSUR#680581  | Puthenmadamkunnu Rd
           | KA#BENGALURU#560030 | Sattar Layout
           
This way we can achieve 4 levels of granularity 
We can query our table with the condition expression  
PK = <Country> AND begins_with(SK, '<State>#')
PK = <Country> AND begins_with(SK, '<State>#<City>#')
========================================================================================================================================
Strategies for many-to-many relationships

If your table has students & classes, you may have one access pattern where you want to fetch a student and the student’s schedule, 
and you may have a different access pattern where you want to fetch a class and all the students in the class. This is the main 
challenge of many-to-many access patterns.

We will cover four strategies for modeling many-to-many relationships with DynamoDb

Strategy 1
Shallow duplication
We can duplicate some data in the new items which helps us identify the main item.
Lets say we have a table and the partition keys are STUDENT#antony, STUDENT#srikar, CLASS#physics
In the CLASS# item we maintain a list attribute that has the student names and hence we are shallow duplicating the items. 
Using the student names in the list we can fetch the student item if necessary.

The shallow duplication strategy works when 
  - There is a limited number of related entities in the duplicated relationship.
  - The duplicated information is immutable.
--------------------------------------------------------------------------------------------------------------------------------------
Strategy 2
Adjacency list

PK             | SK             | SCORE | TEACHER | DOB
CLASS#PHYSICS  | STUDENT#ANTONY | 86    |         |
               | STUDENT#SAI    | 90    |
               | CLASS#PHYSICS  |       | Karthik |
CLASS#CHEM     | STUDENT#ANTONY | 72    |         |
STUDENT#ANTONY | STUDENT#ANTONY |       |         | 27/07/1996

Using the PK we can get all the students taking the particular class. Now lets create a global secondary index and use the SK in our primary table
as its PK. Our index would look like

Partition Key: SK | Sort Key: PK  | SCORE | TEACHER | DOB
STUDENT#ANTONY    | CLASS#PHYSICS | 86    |         |
                  | CLASS#CHEM    | 72    |         |
                  | STUDENT#ANTONY|       |         | 27/07/1996
STUDENT#SAI       | CLASS#PHYSICS | 90    |         |
CLASS#PHYSICS     | CLASS#PHYSICS |       | Karthik |

Now using the partition key in the Global secondary index we can find all the classes attended by the student.

--------------------------------------------------------------------------------------------------------------------------------------
Strategy 3
Materialized graph
A graph is made up of nodes and edges. Usually, a node is an object or concept, such as a person, place, or thing. Various nodes are then
connected via edges, which indicate relationships between nodes.

PK          | SK                     | NodeId | GSI1PK 
156         | DATE|1996-07-27|BIRTH  | 156    | DATE|1996-07-27
            | JOB|Developer|INFOSYS  | 156    | JOB|Developer
            | PERSON|156             | 156    | PERSON|156
250         | DATE|1996-07-27|DEATH  | 250    | DATE|1996-07-27
            | JOB|Carpenter|Self     | 250    | JOB|Carpenter
            | PERSON|250             | 250    | PERSON|250
            
If you closely look at the table we will see a global secondary index and you will see DATE|1996-07-27 is significant as we will see that Person 156 was born
that day and Person 250 died that day. The important part about Materialized graph is that every relation is a separate item in the item collection. One 
single item will not have everthing.

-----------------------------------------------------------------------------------------------------------------------------------------
Strategy 4
Normalization and multiple requests

          
